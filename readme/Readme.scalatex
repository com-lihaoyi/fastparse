@import Main._

@val tests = wd/'fastparse/'shared/'src/'test/'scala/'fastparse
@val main = wd/'fastparse/'shared/'src/'main/'scala/'fastparse
@sect("FastParse 0.1.0", "Fast to write, Fast running Parsers in Scala")
    @hl.ref(tests/"MathTests.scala", "val number", "val tests")
    @hl.ref(tests/"MathTests.scala", Seq("def check", "check"))
    @div(id := "splashdiv")
    @script(raw("""demo.DemoMain().math(document.getElementById("splashdiv"))"""))
    @p
        FastParse is a parser-combinator library for Scala that lets you quickly and easily write recursive descent parsers in Scala. Features include:

    @ul
        @li
            Up to 1/5 the speed of a hand-written parser, 100x faster than @a("scala-parser-combinators", href:="https://github.com/scala/scala-parser-combinators"), comparable (though slightly slower than) @a("Parboiled2", href:="https://github.com/sirthias/parboiled2")
        @li
            1/10th the size of a hand-written parser
        @li
            Automatic, excellent error-reporting and diagnostics.
        @li
            Zero allocations during a parse
        @li
            Compatible with both Scala-JVM and Scala.js

    @sect{Getting Started}
        @p
            To begin using FastParse, add

        @hl.scala
            "com.lihaoyi" %% "fastparse" % "0.1.0"

        @p
            To your SBT configuration. To use with Scala.js, you'll need
        @hl.scala
            "com.lihaoyi" %%% "fastparse" % "0.1.0"

    @sect{Writing Parsers}
        @sect{Basic}
            @p
                The simplest parser matches a single string:

            @hl.ref(tests/"ExampleTests.scala", Seq("'simple", ""))

            @p
                Such a parser returns a @hl.scala{Result.Success} if the input matches the string, and otherwise returns a @hl.scala{Result.Failure}.
            @p
                As you can se, by default the @hl.scala{Success} contains a @hl.scala{(): Unit}, unless you use @sect.ref{Capturing} or @sect.ref{Map} described below. Also, apart from the structured data of the failure, @hl.scala{Failure} also contains a nice human-readable trace of the parse showing the stack of parsers which were in progress when the parse failed.

            @sect{Sequence}

                @hl.ref(tests/"ExampleTests.scala", Seq("'sequence", ""))

                @p
                    You can combine two parsers with the @hl.scala{~} operator. This creates a new parser that only succeeds if both left and right parsers succeed one after another.

            @sect{Repeat}
                @hl.ref(tests/"ExampleTests.scala", Seq("'repeat", ""))

                @p
                    The @hl.scala{.rep} method creates a new parser that attempts to parse the given parser zero or more times. You can optionally provide an argument to @hl.scala{.rep} which acts as a separator between the usages of the original parser, or use @hl.scala{.rep1} if you want to parse something one or more times.

            @sect{Optional}
                @hl.ref(tests/"ExampleTests.scala", Seq("'option", ""))

                @p
                    Similar to @hl.scala{.rep} is @hl.scala{.?}, which creates a new parser that attempts to parse the given parser zero or 1 times.

            @sect{Either}
                @hl.ref(tests/"ExampleTests.scala", Seq("'either", ""))
                @p
                    The @hl.scala{|} operator tries the parser on the left, and if that fails, tries the one on the right, failing only if both parsers fail.

            @sect{End, Start}
                @hl.ref(tests/"ExampleTests.scala", Seq("'end", ""))

                @p
                    The @hl.scala{End} parser only succeeds if at the end of the input string. By default, a @hl.scala{Parser} does not need to consume the whole input, and can succeed early consuming a portion of it (exactly how much input was consumed is stored in the @hl.scala{Success#index} attribute). By using @hl.scala{End}, we can make the parse fail if it doesn't consume everything

                @p
                    There is also a similar @hl.scala{Start} parser, which only succeeds at the start of the input
                @hl.ref(tests/"ExampleTests.scala", Seq("'start", ""))
            @sect{Capturing}
                @hl.ref(tests/"ExampleTests.scala", Seq("'capturing", ""))
                @p
                    So far, all the parsers go over the input text but do not return any useful value: the @hl.scala{Success#value} attribute was always @hl.scala{()}. In order to make them do so, you use the @hl.scala{.!} operation to capture the section of the input string the parser parsed.
                @p
                    Note the types of each parser:
                @ul
                    @li
                        @hl.scala{capture1} is a @hl.scala{Parser[String]}
                    @li
                        @hl.scala{capture2} is a @hl.scala{Parser[(String, String)]}
                    @li
                        @hl.scala{capture3} is a @hl.scala{Parser[(String, String, String)]}
                    @li
                        @hl.scala{captureRep} is a @hl.scala{Parser[Seq[String]]}
                    @li
                        @hl.scala{captureOpt} is a @hl.scala{Parser[Opt[String]]}
                @p
                    In general, if you have a parser of type @hl.scala{TupleN}, capturing one more section turns it into a @hl.scala{TupleN+1}. Furthermore, if you capture within a @hl.scala{.rep} or @hl.scala{.?} optional parser, it becomes a @hl.scala{Parser[Seq[T]]} or @hl.scala{Parser[Option[T]]} respectively
            @sect{AnyChar}
                @hl.ref(tests/"ExampleTests.scala", Seq("'anychar", ""))

                @p
                    This parser parses any single character successfully.

            @sect{Positive Lookahead}
                @hl.ref(tests/"ExampleTests.scala", Seq("'lookahead", ""))
                @p
                    The @hl.scala{&(...)} operator wraps a parser, only succeeds if it succeeds, but consumes no input. Useful for doing checks like "these characters must be followed by a whitespace, but don't consume the whitespace"

            @sect{Negative Lookahead}
                @hl.ref(tests/"ExampleTests.scala", Seq("'neglookahead", ""))
                @p
                    The @hl.scala{!...} operator wraps a parser and only succeeds of it fails, also consuming no input. Useful to combine with other parsers like @sect.ref{AnyChar} to restrict the things that they can parse.
            @sect{Map}
                @hl.ref(tests/"ExampleTests.scala", Seq("'map", ""))
                @p
                    Up till now, we've only dealt with
                @ul
                    @li
                        @hl.scala{Parser[Unit]}: the default case
                    @li
                        @hl.scala{Parser[String]}: after capturing something with @hl.scala{.!}
                    @li
                        @hl.scala{Parser[TupleN[String]]}: capturing multiple things in series
                    @li
                        @hl.scala{Parser[Seq[String]]}, @hl.scala{Parser[Option[String]]}: capturing things in @hl.scala{.rep} and @hl.scala{.?}

                @p
                    @hl.scala{.map} lets you convert an arbitrary @hl.scala{Parser[T]} into a @hl.scala{Parser[V]} by providing a @hl.scala{T => V} function. This is useful for converting the strings and tuples/seqs/options of strings into more useful data-structures
        @sect{Intrinsics}
            @p
                In theory, all possible parsers can be put together using the above tools. In practice, a few more tools are provided for convenience or performance:

            @sect{CharPred}
                @hl.ref(tests/"ExampleTests.scala", Seq("'charPred", ""))
                @p
                    @hl.scala{CharPred} takes a @hl.scala{Char => Boolean} predicate and creates a parser that parses any single character that satisfies that predicate. e.g. you can use any of the helpful methods on @hl.scala{scala.Char} to check if a @hl.scala{Char} @hl.scala{isUpper}, @hl.scala{isDigit}, @hl.scala{isControl}, etc. etc.

                @p
                    Note that this builds a high-performance bit-packed lookup table, the size of the range of valid characters, up to 65k. That means that creating a parser like this has a one-time cost in terms of memory (up to 8k bytes) and time. This should not matter as FastParse parsers are long-lived and re-usable, though you may want to consciously avoid creating too many of these repeatedly.

            @sect{CharIn}
                @hl.ref(tests/"ExampleTests.scala", Seq("'charIn", ""))
                @p
                    Similar to @sect.ref{CharPred}, except you pass in sequences of valid characters rather than a predicate.
                
                @p
                    As a result, it's much faster to execute than if you had used @hl.scala{"a" | "b" | "c" | "d" | ...} to combine a bunch of single-character parsers together. The same warning as @sect.ref{CharPred} about the one time cost-of-construction applies.

            @sect{CharsWhile}
                @hl.ref(tests/"ExampleTests.scala", Seq("'charsWhile", ""))
                @p
                    A repeated version of @sect.ref{CharPred}: this parser continually chomps away at characters as long as they continue passes the given predicate.

                @p
                    This is a very fast parser, ideal for quickly consuming large numbers of characters. The same warning as @sect.ref{CharPred} about the one time cost-of-construction applies.

            @sect{StringIn}
                @hl.ref(tests/"ExampleTests.scala", Seq("'stringIn", ""))

                @p
                    Quickly parses one of any number of strings that you give it. Behind the scenes, it converts the list of strings into a Trie so it can attempt to parse all of them in a single pass.

                @p
                    As a result, this is much faster to execute than if you had combined the individual strings with @hl.scala{"cow" | "cattle" | ...}.
        @sect{Cuts}
            @p
                A "cut" is a marker in a recursive-descent parser that states "you cannot backtrack past this point". Although in theory it allows you to save on memory usage by discarding earlier portions of the input, in FastParse this operator is mostly used to improve on the quality of error reporting.

            @sect{No Cuts}
                @hl.ref(tests/"ExampleTests.scala", Seq("'nocut", ""))
                @p
                    Above we have a naive scala definition parser: it either parses a @hl.scala{val} or @hl.scala{def}, a space, and its (lower-case only) name. On a success this works as expected, and extracts the name. However, on a failure, something odd happens: the deepest parser on-failure is shown to be the entire @sect.ref{Either}, rather than just the @hl.scala{alpha} that came after @hl.scala{"val "}. Why is that?

                @p
                    By default, the parse has an opportunity to backtrack whenever it enters a 

                @ul
                    @li
                        @hl.scala{p1 | p2}: If @hl.scala{p1} fails, it tries @hl.scala{p2}

                    @li
                        @hl.scala{p.rep}, @hl.scala{p.?}: If parsing with @hl.scala{p} fails, it backtracks out of the failed parse and tries to parse whatever comes after the repeat/optional.
                @p
                    e.g. in the case of @hl.scala{p1 | p2}, if it tries to parse @hl.scala{p1} and fails, it then tries to parse @hl.scala{p2}. If @i{that} fails, all that FastParse knows is that one of them should have succeeded. Specifically, FastParse does @i{not} know that after successfully parsing @hl.scala{"val "}, that only the left branch of the @sect.ref{Either} is viable! Thus it has no choice but to offer both alternatives in the error message.

            @sect{Cuts}
                @hl.ref(tests/"ExampleTests.scala", Seq("'withcut", ""))

                @p
                    Cuts are added using the @hl.scala{~!} operator, which is similar to the @sect.ref{Sequence} operator @hl.scala{~}. Once the parse has crossed a cut, it can no longer backtrack past the point at which the cut occured. Hence, in this case you can see that it no longer backtracks to index 0, out of the enclosing @sect.ref{Either} parser and offering that in the error trace. Instead, it shows a much more precise error: at index @hl.scala{4}, expecting one of the small set of alphanumeric characters.
                @p
                    In general, if you know that a parser is "committed" to one branch after parsing to a certain point, adding a cut will greatly improve the error message by ensuring that the parser @i{itself} knows that. Good places to add cuts include places like after keywords in a programming language parser, where a keyword can be followed by only one thing and anything else is an error.
            @sect{Rep Cuts}

                @hl.ref(tests/"ExampleTests.scala", Seq("'repnocut", ""))

                @p
                    A similar problem occurs inside @sect.ref{Repeat} or @sect.ref{Optional} parsers, where the parser will give up and backtrack out if it fails, even if it really should succeed. Again, adding cuts would result in a more precise error message:

                @hl.ref(tests/"ExampleTests.scala", Seq("'repcut", ""))

                @p
                    Another case where you may want to pay attention is when you are using delimiters with your @hl.scala{.rep} calls: 

                @hl.ref(tests/"ExampleTests.scala", Seq("'delimiternocut", ""))

                @p
                    in many (but not all!) cases, if a delimiter is parsed, you want to commit to parsing one more iteration of the @sect.ref{Repeat}. However, by default, it backtracks out of the @sect.ref{Repeat} entirely and starts trying to parse the next item in sequence (in this case the @hl.scala{")"} giving the behavior shown above.

                @p
                    With a cut, the error is improved:

                @hl.ref(tests/"ExampleTests.scala", Seq("'delimitercut", ""))

    @sect{Example Parsers}
        @p
            Above, we've already covered all the individual bits and pieces that make writing a parser possible. But how does that fit together? Let's take a look at some examples.

        @sect{Math}
            @hl.ref(tests/"MathTests.scala", "val number", "val tests")


            @p
                This is a small arithmetic expression parser, the same one shown at the top of this page. It parses only whole integers, parentheses, @hl.scala{+-*/}, and no whitespace.
            @p
                Things to note:

            @ul
                @li
                    The various sub-parsers are all of type @hl.scala{Parser[Int]}, indicating that they result in an @hl.scala{Int} if successful. Many of the type annotations could be removed due to type-inference, but they're shown here for clarity
                @li
                    @hl.scala{divMul} and @hl.scala{addSub} are separated out, in order to properly account for precedence
                @li
                    We evaluate the expression as the parse progresses, meaning we never actually build an tree structure from the input string
                @li
                    In order to convert the parsed strings to integers, we @hl.scala{map} on the @hl.scala{eval} function, which itself is defined earlier:

            @hl.ref(tests/"MathTests.scala", "def eval", "val number")

            @p
                This is a small example, but it works. We check it using a helper to verify that every parse results in the expected integer:

            @hl.ref(tests/"MathTests.scala", "def check")

            @p
                Try it out yourself! Remember that it does not handle whitespace:

            @div(id := "mathdiv")
            @script(raw("""demo.DemoMain().math(document.getElementById("mathdiv"))"""))

        @sect{Json}          
            @hl.ref(tests/"JsonTests.scala", "Here is the parser", "val tests")

            @p
                This is a somewhat larger example than the math parser shown above. In it, we parse a JSON expression from a string, including all the proper handling for whitespace and error-handling built in.

            @p
                Things to note:

            @ul
                @li
                    We use cuts (@hl.scala{~!}) liberally in order to improve the quality of errors. Anywhere there's an @sect.ref{Either} or @sect.ref{Repeat}, the children have cuts once the parse has progressed far enough backtracking isn't an option.
                @li 
                    We use @hl.scala{CharIn} and @hl.scala{CharsWhile} quite a lot, in order to speed up the common case of consuming lots of boring characters.
                @li
                    In @hl.scala{strChars}, we break out of @hl.scala{CharsWhile} closing quote (@hl.scala{'"'}) or whenever we see the start of an escape sequence (@hl.scala{'\'}). Although @hl.scala{CharsWhile} can't process these multi-char sequences, we let the @hl.scala{escape} parser deal with these before trying to fall back to @hl.scala{strChars} after. This lets us speed up the "common" case of consuming large numbers of non-escape characters, while still properly handling escapes.
                @li
                    We use @hl.scala{.map} to convert the various things we parse into instances of our own @hl.scala{Js.Val} JSON AST:


            @hl.ref(tests/"JsonTests.scala", "object Js {", "Here is the parser")

            @p
                We can verify that this parser builds the JSON tree that we expect:

            @hl.ref(tests/"JsonTests.scala", Seq("'jsonExpr", ""))

            @p
                And that it provides good error messages in the case of mal-formed JSON, even for moderately-sized fragemnts

            @val failPath = Seq("'fail", "* -", "* -", "* -", "* -", "* -", "* -", "\"\"\"", "")    
            @hl.ref(tests/"JsonTests.scala", failPath, "\"\"\"")

            @hl.ref(tests/"JsonTests.scala", failPath ++ Seq("\"\"\"", "\"\"\"", ""), "\"\"\"")            

            @p
                Here, we're missing a square bracket after the @hl.scala{"phoneNumbers"} key, and so the parser expects to find a single JSON expression. It finds a JSON object, and then fails reporting that it expected to find the next key (a string), but instead found @hl.scala{"{\n"} at that index.

            @p
                Try it out!

            @div(id := "jsondiv")
            @script(raw("""demo.DemoMain().json(document.getElementById("jsondiv"))"""))

    @sect{API Highlights}

        @sect{Parser[T]}
            @p
                Fastparse revolves around @hl.scala{Parser[T]}s: a parser that can attempt to parser a value @hl.scala{T} from an input string. These are defined as:

            @hl.ref(main/"Parsing.scala", "trait Parser", "trait ParserApi")
            @p
                The main external API is @hl.scala{.parse}. As you can see, apart from the @hl.scala{input} parameter, there are a few parameters that you can use to configure the parse. Apart from that, each @hl.scala{Parser[T]} needs to implement @hl.scala{parseRec} which is a less-convenient but more-performant version that FastParse uses internally when performing a parse.
            @p
                Although the core of @sect.ref{Parser[T]} is simple, a lot of additional functionality is included in the @hl.scala{ParserApi[T]} trait in order to make constructing parsers convenient and concise.

        @sect{ParserApi[T]}
            @p
                Apart from the core @hl.scala{Parser}, FastParse includes a large set of operations that you can perform on a @hl.scala{Parser} to make composing them more pleasant. These all live in @hl.scala{ParserApi}:

            @hl.ref(main/"Parsing.scala", "trait ParserApi", "trait ParserApiImpl")
            
            @p
                There are essentially all short-hand constructors for the parsers in the @hl.scala{object Parser} companion. This is the list of operators that you have available when writing your own parsers using FastParse.

        @sect{Results}
            @p
                The two kinds of @hl.scala{Result}s let you pattern match to extract the most commonly-used values: for a success, you can extract the resultant value, while a failure provides the last parser which failed. Both also provide the index into the string where the parse succeeded or failed.

            @p
                Apart from that, @hl.scala{Result}s also provide other useful information about a parse:

            @hl.ref(main/"Parsing.scala", "trait Success", "object Success")
            @hl.ref(main/"Parsing.scala", "trait Failure", "object Failure")

    @sect{Performance}
        @p
            FastParse will never be able to compete with hand-written recursive descent parsers for speed. However, it's no slouch either; here's a comparison of FastParse with alternatives, using Parboiled2's JSON parsing benchmark:

        @table(width := "100%")
            @thead
                @th{Benchmark}@th{Score}@th{Error}
            @tbody
                @tr
                    @td{fastparse}@td{80.536}@td{± 0.942}
                @tr
                    @td{fastparse-no-trace}@td{89.873}@td{± 0.875}
                @tr
                    @td{argonaut}@td{164.092}@td{± 2.869}
                @tr
                    @td{json4s-jackson}@td{285.637}@td{± 3.954}
                @tr
                    @td{json4s-native}@td{142.964}@td{± 2.076}
                @tr
                    @td{parboiled2}@td{87.586}@td{± 1.176}
                @tr
                    @td{scala-parser-combinators}@td{0.976}@td{± 0.018}
                @tr
                    @td{spray-json}@td{189.784}@td{± 2.825}


        @p
            These numbers are the number of iterations/second of parsing a sample @code{test.json} file, averaged over 200 runs. As you can see, the FastParse based parser comes within a factor of 4 of the fastest hand written parser (Jackson), is just as fast as the Parboiled2 based parser (slightly faster/slower depending if full tracing is enabled), and is almost 100x faster than the scala-parser-combinators library.

        @p
            In exchange for the perf hit compared to hand-rolled solutions, you get the @sect.ref("Json", "short, super-simple parser definition"), and excellent error free error reporting. While for super-high-performance use cases you may still want a hand-rolled parser, for many ad-hoc situations a FastParse parser would do just fine.

        @p
            A similar speed ratio can be seen in parsing a @a("sample Scala file", href:="https://github.com/scala-js/scala-js/blob/master/compiler/src/main/scala/org/scalajs/core/compiler/GenJSCode.scala") using FastParse, Parboiled2 and Scalac's inbuilt hand-written Scala-language parser:

        @table(width := "100%")
            @thead
                @th{Benchmark}@th{Score}@th{Error}
            @tbody
                @tr
                    @td{fastparse}@td{338}@td{2.51}
                @tr
                    @td{fastparse-no-trace}@td{414}@td{26.4}
                @tr
                    @td{parboiled2}@td{1249}@td{87.8}
                @tr
                    @td{scalac}@td{5406}@td{260}

        @p
            These numbers are the number of iterations over 30 seconds. FastParse performs worse here, at 13x slower than Scalac's in-built parser, and 3x slower than the equivalent Parboiled2-based parser. Depending on what you're doing, that may or may not be a problem.

    @sect{Internals}
        @p 
            FastParse's internals are straightforward, at less than 1000 lines of code. Nonetheless, its design is unlike any other combinator library I've seen: externally immutable, pure-functional parser-combinators with mutable, highly-optimized internals.

        @sect{Fast Interpreter}
            @p
                FastParse is designed as a fast, immutable interpreter. That means
            @ul
                @li
                    It does not do significant transformations of the grammar. The structure of the parser you define is the structure that will run. No transformation at compile time, no transformations at run-time.
                @li
                    It provides fast primitives like @sect.ref{CharsWhile}, that you can drop in many places to speed up otherwise slow bulk operations (e.g. parsing whitespace, identifiers).
                @li
                    Error reported is straightforward: the last index that it does not backtrack out of is the index that is reported, and the parser at that point is the parser that is reported.

            @p
                In theory, it could be possible to perform either compile-time or initialization-time (before actually parsing) optimizations on the parser to improve performance. So far, I have not managed to find a scheme that has a significant improvement at an acceptable cost in terms of complexity. Apart from trivial de-sugarings (e.g. merging together @hl.scala{(p1 | p2) | p3} into a single @hl.scala{Either} node) what you write is what gets run

        @sect{External Immutabiliy}

            @p
                FastParse presents a pure-functional, immutable external API to the user. That means that you can call @hl.scala{Parser[T]#parse} and not worry about having to set up neccessary state or instantiating objects. You take a @hl.scala{Parser[T]}, call @hl.scala{.parse}, and get a @hl.scala{Success[T]} or @hl.scala{Failure}

            @p
                However, immutability poses a challenge: immutability usually involves lots of "copy & update" operations rather than "mutation" operations, and on the JVM that means excessive garbage generation and collection. This is harmful for performance.

            @p
                Thus FastParse performs some tricks internally to save allocations: the immutable @hl.scala{Parser.Success} and @hl.scala{Parser.Failure} result types are actually interfaces hiding @hl.scala{Parser.Success.Mutable} and @hl.scala{Parser.Failure.Mutable} implementations, which have entirely mutable fields. 

            @p
                This means that the same @hl.scala{Parser.Success.Mutable} and @hl.scala{Parser.Failure.Mutable} objects are shared throughout an entire parsing run, mutated as the parse progresses, while the external user only sees an immutable facade. This also means that a run of the large-and-complex @sect.ref{scalaparser} on a hundreds-of-kb source file results in exactly @i{three} allocations in all: one @hl.scala{Parser.Success.Mutable}, one @hl.scala{Parser.Failure.Mutable}, and one @hl.scala{Ctx} object holding them together. 

        @sect{Internal Optimizations}
            @p
                FastParse does some things that take advantage of the type-directed nature of the result-aggregation: while @hl.scala{Parser[T].rep} returns a @hl.scala{Parser[Seq[T]]} for an arbitrary @hl.scala{T}, there is a short circuit such that @hl.scala{Parser[Unit].rep} simple returns @hl.scala{Parser[Unit]}. This lets the common case of "parsing things, not caring about the result" avoid the allocation, while still allowing you to stick some other type in there (e.g. @hl.scala{Any}) if you really do care about the bucket-of-@hl.scala{Unit}s.

            @p
                FastParse also takes advantage of the fact that @hl.scala{Parser}s are immutable. That makes it feasible to make instantiation mildly-expensive, since each one only gets instantiated once rather than per-parse. As an example, @sect.ref{CharIn}, @sect.ref{CharPred} and @sect.ref{CharsWhile} all have their predicate converted to an identical bit-set to make character lookups extremely fast. Similarly, @sect.ref{StringIn} gets converted into a Trie in order to allow one-pass matching of dozens of strings at the same time. 
            @p
                These operations are not cheap: the bitsets easily take a few KB of memory each, and involve 65k iterations to fill them in. However, since @hl.scala{Parser}s are immutable, this one-time-cost goes from "ridiculous" to "acceptable". All these internal optimizations are completely opaque to the user, who (apart from performance) never need to think about them.


    @sect{Comparisons}
        @p    
            FastParse differs from all other parser-combinator libraries in the Scala universe, in quite substantial ways:

        @ul
            @li
                Compared to @a("Parboiled2", href:="https://github.com/sirthias/parboiled2"), FastParse does not use macros to compile-time-generate fast parser code. Rather, it acts as an efficient interpreter, sacrificing a small amount of speed (with a factor of 2) for huge amounts of usability. Parboiled2 in particular has @a("usability problems and bugs", href:="https://groups.google.com/forum/#!msg/scala-internals/4N-uK5YOtKI/9vAdsH1VhqAJ") that make it excruciating difficult to use, and also does not support higher-order rules. FastParse suffers from none of these problems.
            @li
                @a("Parboiled1", href:="https://github.com/sirthias/parboiled/wiki") is a Java library, and does not/cannot work on Scala.js
            @li
                @a("scala-parser-combinators", href:="https://github.com/scala/scala-parser-combinators") is similar, but poorly executed. It is ~100x slower than FastParse, has an awkward inheritance-based API, and is full of bugs despite being half a decade old. FastParse is faster, has self-contained pure-functional parsers, and fixes bugs e.g. by having the @hl.scala{.log} operator actually work.

    @sect{scalaparser}
        @p
            scalaparser is a parser for the entire Scala programming language, written using FastParse. This is notable for a few reasons:

        @div(id := "scaladiv")
        @script(raw("""demo.DemoMain().scalaparse(document.getElementById("scaladiv"))"""))
        @ul
            @li
                scalaparser is about 700 lines of code, making it about 1/10th the size of the default parser in @hl.scala{tools.nsc.Global}
            @li
                scalaparser runs about 1/8th the speed of of the default parser in @hl.scala{tools.nsc.Global}
            @li
                scalaparser has excellent error reporting due to proper use of @sect.ref{Cuts}, without any code explicitly dedicated to error reporting

