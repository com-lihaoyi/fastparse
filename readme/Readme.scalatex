@import Main._

@a(
  href:="https://github.com/lihaoyi/fastparse",
  position.absolute,
  top:=0,right:=0,border:=0,
  img(
    src:="https://camo.githubusercontent.com/a6677b08c955af8400f44c6298f40e7d19cc5b2d/68747470733a2f2f73332e616d617a6f6e6177732e636f6d2f6769746875622f726962626f6e732f666f726b6d655f72696768745f677261795f3664366436642e706e67",
    alt:="Fork me on GitHub"
  )
)

@val tests = wd/'fastparse/'shared/'src/'test/'scala/'fastparse
@val main = wd/'fastparse/'shared/'src/'main/'scala/'fastparse
@val bytetests = wd/'byteparse/'shared/'src/'test/'scala/'byteparse
@val bytemain = wd/'byteparse/'shared/'src/'main/'scala/'byteparse

@sect("FastParse " + fastparse.Constants.version, "Fast to write, Fast running Parsers in Scala")
    @hl.ref(tests/"MathTests.scala", "val number", "val tests")
    @hl.ref(tests/"MathTests.scala", Seq("def check", "check"))
    @div(id := "splashdiv")
    @script(raw("""demo.DemoMain().math(document.getElementById("splashdiv"))"""))
    @p
        FastParse is a parser-combinator library for Scala that lets you quickly and easily write recursive descent parsers in Scala. Features include:

    @ul
        @li
            Up to 1/5 the speed of a hand-written parser, 100x faster than @a("scala-parser-combinators", href:="https://github.com/scala/scala-parser-combinators"), comparable (though slightly slower than) @a("Parboiled2", href:="https://github.com/sirthias/parboiled2")
        @li
            1/10th the size of a hand-written parser
        @li
            Automatic, excellent error-reporting and diagnostics.
        @li
            Zero allocations during a parse
        @li
            Compatible with both Scala-JVM and Scala.js
    @p
         The following sections will introduce you to FastParse and how to use it. You can also watch this talk:
    @iframe(
        src:="https://player.vimeo.com/video/142341803",
        "width".attr:="800",
        "height".attr:="450",
        marginLeft.auto,
        marginRight.auto,
        display.block,
        "frameborder".attr:="0",
        "webkitallowfullscreen".attr:=1,
        "mozallowfullscreen".attr:=1,
        "allowfullscreen".attr:= 1
    )
    @p
        Which will give you a quick 1-hour tour of how to use FastParse, the motivation behind the library, and how it fits into the bigger picture of how programmers parse unstructured text.

    @sect{Getting Started}
        @p
            To begin using FastParse, add

        @hl.scala
            "com.lihaoyi" %% "fastparse" % "@fastparse.Constants.version"

        @p
            To your SBT configuration. To use with Scala.js, you'll need
        @hl.scala
            "com.lihaoyi" %%% "fastparse" % "@fastparse.Constants.version"



    @sect{Writing Parsers}
        @sect{Basic}
            @p
                The simplest parser matches a single string:

            @hl.ref(tests/"ExampleTests.scala", Seq("'simple", ""))

            @p
                Such a parser returns a @hl.scala{Parsed.Success} if the input matches the string, and otherwise returns a @hl.scala{Parsed.Failure}.
            @p
                As you can see, by default the @hl.scala{Parsed.Success} contains a @hl.scala{(): Unit}, unless you use @sect.ref{Capture} or @sect.ref{Map} described below. Also, apart from the structured data of the failure, @hl.scala{Parsed.Failure} also contains a nice human-readable trace of the parse showing the stack of parsers which were in progress when the parse failed. The trace can be obtained via @hl.scala{Parsed.Failure.Extra.trace}.

            @p
                You can also wrap the strings in an @hl.scala{IgnoreCase("...")} if you want the matching to be case-insensitive.

            @sect{Sequence}

                @hl.ref(tests/"ExampleTests.scala", Seq("'sequence", ""))

                @p
                    You can combine two parsers with the @hl.scala{~} operator. This creates a new parser that only succeeds if both left and right parsers succeed one after another.

            @sect{Repeat}
                @hl.ref(tests/"ExampleTests.scala", Seq("'repeat", ""))

                @p
                    The @hl.scala{.rep} method creates a new parser that attempts to parse the given parser zero or more times.
                    If you want to parse something a given number of times, you can use @hl.scala{.rep(min = 2, max = 4)} o
                    r the shorter @hl.scala{.rep(1)} for one or more times,
                    in addition there is @hl.scala{exactly} parameter that if it's defined behaves
                    like @hl.scala{min} and @hl.scala{max} equals to it.
                    You can optionally provide an argument which acts as a separator between the usages of the original parser,
                    such as a comma in @hl.scala{.rep(sep = ",")}.

            @sect{Optional}
                @hl.ref(tests/"ExampleTests.scala", Seq("'option", ""))

                @p
                    Similar to @hl.scala{.rep} is @hl.scala{.?}, which creates a new parser that attempts to parse the given parser zero or 1 times.

            @sect{Either}
                @hl.ref(tests/"ExampleTests.scala", Seq("'either", ""))
                @p
                    The @hl.scala{|} operator tries the parser on the left, and if that fails, tries the one on the right, failing only if both parsers fail.

            @sect{End, Start}
                @hl.ref(tests/"ExampleTests.scala", Seq("'end", ""))

                @p
                    The @hl.scala{End} parser only succeeds if at the end of the input string. By default, a @hl.scala{Parser} does not need to consume the whole input, and can succeed early consuming a portion of it (exactly how much input was consumed is stored in the @hl.scala{Success#index} attribute). By using @hl.scala{End}, we can make the parse fail if it doesn't consume everything

                @p
                    There is also a similar @hl.scala{Start} parser, which only succeeds at the start of the input
                @hl.ref(tests/"ExampleTests.scala", Seq("'start", ""))

            @sect{Pass, Fail}
                @hl.ref(tests/"ExampleTests.scala", Seq("'passfail", ""))

                @p
                    These two parsers always succeed, or always fail, respectively. Neither consumes any input.

            @sect{Index}
                @hl.ref(tests/"ExampleTests.scala", Seq("'index", ""))

                @p
                    Always succeeds, and provides the current index of the parse into the input string. e.g. useful for providing source locations for AST nodes. Consumes no input.

            @sect{Capture}
                @hl.ref(tests/"ExampleTests.scala", Seq("'capturing", ""))
                @p
                    So far, all the parsers go over the input text but do not return any useful value: the @hl.scala{Success#value} attribute was always @hl.scala{()}. In order to make them do so, you use the @hl.scala{.!} operation to capture the section of the input string the parser parsed.
                @p
                    Note the types of each parser:
                @ul
                    @li
                        @hl.scala{capture1} is a @hl.scala{Parser[String]}
                    @li
                        @hl.scala{capture2} is a @hl.scala{Parser[(String, String)]}
                    @li
                        @hl.scala{capture3} is a @hl.scala{Parser[(String, String, String)]}
                    @li
                        @hl.scala{captureRep} is a @hl.scala{Parser[Seq[String]]}
                    @li
                        @hl.scala{captureOpt} is a @hl.scala{Parser[Option[String]]}
                @p
                    In general, if you have a parser of type @hl.scala{TupleN}, capturing one more section turns it into a @hl.scala{TupleN+1}. Furthermore, if you capture within a @hl.scala{.rep} or @hl.scala{.?} optional parser, it becomes a @hl.scala{Parser[Seq[T]]} or @hl.scala{Parser[Option[T]]} respectively
            @sect{AnyChar}
                @i
                    See also @hl.scala{AnyElem} in @sect.ref{Abstraction}
                @hl.ref(tests/"ExampleTests.scala", Seq("'anychar", ""))

                @p
                    This parser parses any single character successfully.

            @sect{Positive Lookahead}
                @hl.ref(tests/"ExampleTests.scala", Seq("'lookahead", ""))
                @p
                    The @hl.scala{&(...)} operator wraps a parser, only succeeds if it succeeds, but consumes no input. Useful for doing checks like "these characters must be followed by a whitespace, but don't consume the whitespace"

            @sect{Negative Lookahead}
                @hl.ref(tests/"ExampleTests.scala", Seq("'neglookahead", ""))
                @p
                    The @hl.scala{!...} operator wraps a parser and only succeeds if it fails, also consuming no input. Useful to combine with other parsers like @sect.ref{AnyChar} to restrict the things that they can parse.
            @sect{Map}
                @hl.ref(tests/"ExampleTests.scala", Seq("'map", ""))
                @p
                    Up till now, we've only dealt with
                @ul
                    @li
                        @hl.scala{Parser[Unit]}: the default case
                    @li
                        @hl.scala{Parser[String]}: after capturing something with @hl.scala{.!}
                    @li
                        @hl.scala{Parser[TupleN[String]]}: capturing multiple things in series
                    @li
                        @hl.scala{Parser[Seq[String]]}, @hl.scala{Parser[Option[String]]}: capturing things in @hl.scala{.rep} and @hl.scala{.?}

                @p
                    @hl.scala{.map} lets you convert an arbitrary @hl.scala{Parser[T]} into a @hl.scala{Parser[V]} by providing a @hl.scala{T => V} function. This is useful for converting the strings and tuples/seqs/options of strings into more useful data-structures.
            @sect{FlatMap}
                @hl.ref(tests/"ExampleTests.scala", Seq("'flatMap", ""))

                @p
                    @hl.scala{.flatMap} allows you to dynamically choose a parser to continue with, given the result of the current parser. The example above uses it to parse balanced XML tags. @hl.scala{.flatMap} can be used to parse indentation-based grammars, and is used to do so in @a("Scalatex", href:="http://lihaoyi.github.io/Scalatex/").

                @p
                    Note that the function given to @hl.scala{.flatMap} is evaluated every time this parser is tried. You should be conscious of the cost of re-creating the resultant parser every time, since FastParse parsers are somewhat expensive to initialize despite being fast per-run. If possible, store the parsers somewhere before-hand or memo-ize/cache them to avoid initializing them wastefully.
            @sect{Filter}
                @hl.ref(tests/"ExampleTests.scala", Seq("'filter", ""))

                @p
                    @hl.scala{.filter} allows you to supply a predicate @hl.scala{T => Boolean} which is applied to the successful result of the current parser. If the predicate is true the filtered parser succeeds otherwise it fails. The example above uses @hl.scala{.filter} on digits to parse only even numbers successfully while odd numbers will fail. If the current parser fails then that failure is simply passed along.
            @sect{Opaque}
                @p
                    Sometimes it's useful to hide parser's implementation details and provide a higher-level error message. @hl.scala{.opaque} achieves exactly that.
                @hl.ref(tests/"ExampleTests.scala", Seq("'opaque", ""))
                @p
                    @hl.scala{.opaque} wraps the target parser in an @hl.scala{Opaque} combinator, which only succeeds or fails as a single entity and leaves no traces of underlying parsers on the stack.

            @sect{Log}
                @hl.ref(tests/"MiscTests.scala", Seq("'logging", ""))

                @p
                    @sect.ref{Debugging Parsers} is often done with the @hl.scala{.log()} method, which logs output whenever the parser is tried, and when it succeeds or fails, together with the location and other data when these things happen (traces on failures, results on successes, the presence of @sect.ref{Cuts}, ...). You can define custom loggers as we've done here, or you can just leave it to by default print to stdout.

                @p
                    Generally, if a parser is doing something wrong, the workflow is:

                @ul
                    @li
                        Add a @hl.scala{.log()} to the parser which is misbehaving
                    @li
                        See where it's being tried, and what it's result (success/failure) is, and confirm that it is misbehaving.
                    @li
                        Look at the parsers it's made of; which one of them is misbehaving and causing the larger parser to misbehave?
                    @li
                        Add @hl.scala{.log()}s to all of them
                    @li
                        Identify which of the sub-parsers is misbehaving
                    @li
                        Repeat
                @p
                    It's a non-trivial process, but it is generally not hard to figure out what's happening this way.

        @sect{Intrinsics}
            @p
                In theory, all possible parsers can be put together using the above tools. In practice, a few more tools are provided for convenience or performance:

            @sect{CharPred}
                @i
                    See also @hl.scala{ElemPred} in @sect.ref{Abstraction}
                @hl.ref(tests/"ExampleTests.scala", Seq("'charPred", ""))
                @p
                    @hl.scala{CharPred} takes a @hl.scala{Char => Boolean} predicate and creates a parser that parses any single character that satisfies that predicate. e.g. you can use any of the helpful methods on @hl.scala{scala.Char} to check if a @hl.scala{Char} @hl.scala{isUpper}, @hl.scala{isDigit}, @hl.scala{isControl}, etc. etc.

                @p
                    Note that this builds a high-performance bit-packed lookup table, the size of the range of valid characters, up to 65k. That means that creating a parser like this has a one-time cost in terms of memory (up to 8k bytes) and time. This should not matter as FastParse parsers are long-lived and re-usable, though you may want to consciously avoid creating too many of these repeatedly.

            @sect{CharIn}
                @i
                    See also @hl.scala{ElemIn} in @sect.ref{Abstraction}
                @hl.ref(tests/"ExampleTests.scala", Seq("'charIn", ""))
                @p
                    Similar to @sect.ref{CharPred}, except you pass in sequences of valid characters rather than a predicate.

                @p
                    As a result, it's much faster to execute than if you had used @hl.scala{"a" | "b" | "c" | "d" | ...} to combine a bunch of single-character parsers together. The same warning as @sect.ref{CharPred} about the one time cost-of-construction applies.

            @sect{CharsWhile}
                @i
                    See also @hl.scala{ElemWhile} in @sect.ref{Abstraction}
                @hl.ref(tests/"ExampleTests.scala", Seq("'charsWhile", ""))
                @p
                    A repeated version of @sect.ref{CharPred}: this parser continually chomps away at characters as long as they continue passes the given predicate.

                @p
                    This is a very fast parser, ideal for quickly consuming large numbers of characters. The same warning as @sect.ref{CharPred} about the one time cost-of-construction applies.

            @sect{StringIn}
                @i
                    See also @hl.scala{SeqIn} in @sect.ref{Abstraction}
                @hl.ref(tests/"ExampleTests.scala", Seq("'stringIn", ""))

                @p
                    Quickly parses one of any number of strings that you give it. Behind the scenes, it converts the list of strings into a Trie so it can attempt to parse all of them in a single pass.

                @p
                    As a result, this is much faster to execute than if you had combined the individual strings with @hl.scala{"cow" | "cattle" | ...}.
        @sect{Cuts}
            @p
                A "cut" is a marker in a recursive-descent parser that states "you cannot backtrack past this point". Although in theory it allows you to save on memory usage by discarding earlier portions of the input, in FastParse this operator is mostly used to improve on the quality of error reporting.

            @sect{No Cuts}
                @hl.ref(tests/"ExampleTests.scala", Seq("'nocut", ""))
                @p
                    Above we have a naive scala definition parser: it either parses a @hl.scala{val} or @hl.scala{def}, a space, and its (lower-case only) name. On a success this works as expected, and extracts the name. However, on a failure, something odd happens: the deepest parser on-failure is shown to be the entire @sect.ref{Either}, rather than just the @hl.scala{alpha} that came after @hl.scala{"val "}. Why is that?

                @p
                    By default, the parse has an opportunity to backtrack whenever it enters a

                @ul
                    @li
                        @hl.scala{p1 | p2}: If @hl.scala{p1} fails, it tries @hl.scala{p2}

                    @li
                        @hl.scala{p.rep}, @hl.scala{p.?}: If parsing with @hl.scala{p} fails, it backtracks out of the failed parse and tries to parse whatever comes after the repeat/optional.
                @p
                    e.g. in the case of @hl.scala{p1 | p2}, if it tries to parse @hl.scala{p1} and fails, it then tries to parse @hl.scala{p2}. If @i{that} fails, all that FastParse knows is that one of them should have succeeded. Specifically, FastParse does @i{not} know that after successfully parsing @hl.scala{"val "}, that only the left branch of the @sect.ref{Either} is viable! Thus it has no choice but to offer both alternatives in the error message.

            @sect{Cuts}
                @hl.ref(tests/"ExampleTests.scala", Seq("'withcut", ""))

                @p
                    Cuts are added using the @hl.scala{~/} operator, which is similar to the @sect.ref{Sequence} operator @hl.scala{~}. Once the parse has crossed a cut, it can no longer backtrack past the point at which the cut occured. Hence, in this case you can see that it no longer backtracks to index 0, out of the enclosing @sect.ref{Either} parser and offering that in the error trace. Instead, it shows a much more precise error: at index @hl.scala{4}, expecting one of the small set of alphanumeric characters.
                @p
                    In general, if you know that a parser is "committed" to one branch after parsing to a certain point, adding a cut will greatly improve the error message by ensuring that the parser @i{itself} knows that. Good places to add cuts include places like after keywords in a programming language parser, where a keyword can be followed by only one thing and anything else is an error.
            @sect{Rep Cuts}

                @hl.ref(tests/"ExampleTests.scala", Seq("'repnocut", ""))

                @p
                    A similar problem occurs inside @sect.ref{Repeat} or @sect.ref{Optional} parsers, where the parser will give up and backtrack out if it fails, even if it really should succeed. Again, adding cuts would result in a more precise error message:

                @hl.ref(tests/"ExampleTests.scala", Seq("'repcut", ""))

                @p
                    Another case where you may want to pay attention is when you are using delimiters with your @hl.scala{.rep} calls:

                @hl.ref(tests/"ExampleTests.scala", Seq("'delimiternocut", ""))

                @p
                    in many (but not all!) cases, if a delimiter is parsed, you want to commit to parsing one more iteration of the @sect.ref{Repeat}. However, by default, it backtracks out of the @sect.ref{Repeat} entirely and starts trying to parse the next item in sequence (in this case the @hl.scala{")"} giving the behavior shown above.

                @p
                    With a cut, the error is improved:

                @hl.ref(tests/"ExampleTests.scala", Seq("'delimitercut", ""))

                @p
                    The @hl.scala{~/} operator can be used without following parser as a shortcut for @hl.scala{~/ Pass}. Compare the previous example with the following one:

                @hl.ref(tests/"ExampleTests.scala", Seq("'endcut", ""))

            @sect{Isolating Cuts}
                @p
                    Because cuts prevent backtracking throughout the entire parser, they make it difficult to compose arbitrary parsers:

                @hl.ref(tests/"ExampleTests.scala", Seq("'composecut", ""))

                @p
                    In the above case, @hl.scala{time1} and @hl.scala{time2} are arbitrary parsers containing @sect.ref{Cuts}. By default, that means that once you've crossed a cut, you can no longer backtrack. However, there are cases where you want to use an existing parser (for example @hl.scala{time1}) in a situation where you want to allow it to backtrack, but you don't want to rewrite it identically but without cuts. In this case it's trivial, but if @hl.scala{time1} was larger you would need to rewrite all of it as well as all of its transitive sub-parsers to make sure that not a single one had a cut inside!

                @p
                    To explicitly isolate a cut to one branch of a parser, place that branch within @hl.scala{NoCut}.  Cuts within that branch will prevent backtracking inside that branch, but if that branch fails alternate branches will be tried as normal.

                @hl.ref(tests/"ExampleTests.scala", Seq("'composenocut", ""))
        @sect{Unapply}
            @p
                @hl.scala{Parser} class has (as many other classes in Scala) a convenient method @hl.scala{unapply}
                which allows to do pattern matching using parsers (like regular expressions) in your code.

                @hl.ref(tests/"ExampleTests.scala", "val capture1", "val captureOpt")

    @sect{Iterator Parsing}
        @p
            In addition to the regular plain parsing you can simply parse streaming data as @hl.scala{Iterator}.
            Just call @hl.scala{.parseIterator} instead of @hl.scala{.parse} in your parser and pass the @hl.scala{Iterator[IndexedSeq[ElemType]]}.
            In contrast to merely @hl.scala{Iterator[Char]} or @hl.scala{Iterator[Byte]} @hl.scala{Iterator} of @hl.scala{IndexedSeq}
            represents real case when chunks of data coming from some source (network, lines from file on the disk)
            and improves performance by loading big parts of input immediately, not dividing them into bytes.
        @p
            Parsing process will try to optimize the memory consumption using the information
            about @sect.ref{Cuts}, @sect.ref{Capture} and other special behaviors of simple parsers.
            It maintains an internal buffer of the iterator segments it has read so far,
            and then uses @hl.scala{Cuts} to determine when the parser no longer can backtrack past certain points,
            and discards the parts of buffered input it no longer needs.
            This discarding happens approximately after every ~ (especially ~/) or iteration of .rep.
        @p
            Anyway, you can use the simple rule to improve the performance in the Iterator parsing -
            every cut in your parser possibly reduces the total memory consumption,
            so if you want to write good Iterator parser just add cuts wherever it's possible.

        @p
            @i
                Note also that with Iterator parser you can't use @sect.ref{Tracing}
                as the iterator gets exhausted after the first parsing pass and are not available for a second time.

        @p
            Here's some benchmarks that measure maximum size of inner buffer and execution time during some parsers work.
        @table(width := "100%")
            @thead
                @th{Parser}
                @th{Maximum buffer @br for 1-sized chunk}
                @th{Maximum buffer @br for 1024-sized chunk}
                @th{Size of input}
                @th{Used memory}
            @tbody
                @tr
                    @td{ScalaParse}@td{1555}@td{2523}@td{147894}@td{1.4%}
                @tr
                    @td{PythonParse}@td{2006}@td{2867}@td{68558}@td{3.6%}
                @tr
                    @td{ByteParse}@td{36}@td{1026}@td{786486}@td{0.01%}
                @tr
                    @td{ClassParse}@td{476}@td{1371}@td{332142}@td{0.3%}

        @table(width := "100%")
            @thead
                @th{Parser}
                @th{Score on the plain parsing}
                @th{Score on the iterator parsing @br for 1-sized chunk}
                @th{Score on the iterator parsing @br for 1024-sized chunk}
            @tbody
                @tr
                    @td{ScalaParse}@td{43}@td{33}@td{43}
                @tr
                    @td{PythonParse}@td{1150}@td{600}@td{890}
                @tr
                    @td{ByteParse}@td{195}@td{15}@td{40}
                @tr
                    @td{ClassParse}@td{160}@td{40}@td{100}

         @p
            As you can see parsing of Iterators dramatically reduces (even with quite big size of chunks)
            the amount of memory needed for work and the chunk size directly impact on performance
            because of a large number of requests for data from Iterator in small size chunk case.


    @sect{Example Parsers}
        @p
            Above, we've already covered all the individual bits and pieces that make writing a parser possible. But how does that fit together? Let's take a look at some examples.

        @sect{Math}
            @hl.ref(tests/"MathTests.scala", "val number", "val tests")


            @p
                This is a small arithmetic expression parser, the same one shown at the top of this page. It parses only whole integers, parentheses, @hl.scala{+-*/}, and no whitespace.
            @p
                Things to note:

            @ul
                @li
                    The various sub-parsers are all of type @hl.scala{Parser[Int]}, indicating that they result in an @hl.scala{Int} if successful. Many of the type annotations could be removed due to type-inference, but they're shown here for clarity
                @li
                    @hl.scala{divMul} and @hl.scala{addSub} are separated out, in order to properly account for precedence
                @li
                    We evaluate the expression as the parse progresses, meaning we never actually build an tree structure from the input string
                @li
                    In order to convert the parsed strings to integers, we @hl.scala{map} on the @hl.scala{eval} function, which itself is defined earlier:

            @hl.ref(tests/"MathTests.scala", "def eval", "val number")

            @p
                This is a small example, but it works. We check it using a helper to verify that every parse results in the expected integer:

            @hl.ref(tests/"MathTests.scala", "def check")

            @p
                Try it out yourself! Remember that it does not handle whitespace:

            @div(id := "mathdiv")
            @script(raw("""demo.DemoMain().math(document.getElementById("mathdiv"))"""))
        @sect{Whitespace Handling}
            @hl.ref(tests/"WhiteSpaceMathTests.scala", "val White", "val tests")

            @p
                To handle whitespace and other non-significant characters with FastParse, use the @hl.scala{WhitespaceApi} as a substitue for the normal API that is provided for parsers. This modifies the @hl.scala{~} and @hl.scala{.rep} operators to consume all non-trailing whitespace and ignoring it.

            @p
                Note how you can pass in whatever definition of whitespace you want: here we're passing in a simple @hl.scala{" ".rep}, but in a more sophisticated parser you may wish to include tabs, newlines, comments or even nested comments. The whitespace parser can be arbitrarily complex.

            @p
                Note also how we're importing from @hl.scala{fastparse.noApi} instead of @hl.scala{fastparse.all}, and then substituting it with our one whitespace-consuming parser API. Other than that, the parser is identical except for added whitespace parsers at the start and end of the @hl.scala{expr} rule.

            @p
                Here it is in action:

            @hl.ref(tests/"WhiteSpaceMathTests.scala", "def check")

            @p
                Or try it yourself:

            @div(id := "wsmathdiv")
            @script(raw("""demo.DemoMain().whitespaceMath(document.getElementById("wsmathdiv"))"""))

        @sect{Indentation Grammars}
            @hl.ref(tests/"IndentationTests.scala", "def eval", "val tests")
            @p
                Here is a grammar that is used to parse a simple indentation-based math grammar. To understand the grammar it is trying to parse, it is worth looking at the test data:

            @hl.ref(tests/"IndentationTests.scala", "def check", Seq("check(", "check(", "check("))

            @p
                As you can see, it is basically a prefix math evaluator, where you use indentation to pass the numbers or expressions to each operator to operate on.

            @p
                As for the parser, the novel things are:

            @ul
                @li
                    All the rules live in a class parametrized on the @hl.scala{indent} that is currently in place
                @li
                    At each level, the @hl.scala{factor}s (@hl.scala{number}s or further @hl.scala{block}s) inside a block are separated by a newline and @hl.scala{indent} spaces
                @li
                    The initial top-level @hl.scala{expr} rule starts off with indentation @hl.scala{0}
                @li
                    After parsing an operator, we use @hl.scala{deeper} to figure out how deep the first line of the indented block is.
                @li
                    We then use @hl.scala{.flatMap} to increment the indentation to the new value and parse the @hl.scala{factor}s at that indentation.

            @p
                Note how there is no pre-processing, and no lexining phase where the lexer has to guess where in the token stream to inject synthetic indent and dedent tokens, Everything happens in a single pass.
            @p
                Try it out!
            @div(id := "indentdiv")
            @script(raw("""demo.DemoMain().indentation(document.getElementById("indentdiv"))"""))

        @sect{Json}
            @hl.ref(tests/"JsonTests.scala", "Here is the parser", "val tests")

            @p
                This is a somewhat larger example than the math parser shown above. In it, we parse a JSON expression from a string, including all the proper handling for whitespace and error-handling built in.

            @p
                Things to note:

            @ul
                @li
                    We use cuts (@hl.scala{~/}) liberally in order to improve the quality of errors. Anywhere there's an @sect.ref{Either} or @sect.ref{Repeat}, the children have cuts once the parse has progressed far enough backtracking isn't an option.
                @li
                    We use @hl.scala{CharIn} and @hl.scala{CharsWhile} quite a lot, in order to speed up the common case of consuming lots of boring characters.
                @li
                    In @hl.scala{strChars}, we break out of @hl.scala{CharsWhile} closing quote (@hl.scala{'"'}) or whenever we see the start of an escape sequence (@hl.scala{'\'}). Although @hl.scala{CharsWhile} can't process these multi-char sequences, we let the @hl.scala{escape} parser deal with these before trying to fall back to @hl.scala{strChars} after. This lets us speed up the "common" case of consuming large numbers of non-escape characters, while still properly handling escapes.
                @li
                    We use @hl.scala{.map} to convert the various things we parse into instances of our own @hl.scala{Js.Val} JSON AST:


            @hl.ref(tests/"JsonTests.scala", "object Js {", "Here is the parser")

            @p
                We can verify that this parser builds the JSON tree that we expect:

            @hl.ref(tests/"JsonTests.scala", Seq("'jsonExpr", ""))

            @p
                And that it provides good error messages in the case of mal-formed JSON, even for moderately-sized fragemnts

            @val failPath = Seq("'fail", "* -", "* -", "* -", "* -", "* -", "* -", "\"\"\"", "")
            @hl.ref(tests/"JsonTests.scala", failPath, "\"\"\"")

            @hl.ref(tests/"JsonTests.scala", failPath ++ Seq("\"\"\"", "\"\"\"", ""), "\"\"\"")

            @p
                Here, we're missing a square bracket after the @hl.scala{"phoneNumbers"} key, and so the parser expects to find a single JSON expression. It finds a JSON object, and then fails reporting that it expected to find the next key (a string), but instead found @hl.scala{"{\n"} at that index.

            @p
                Try it out!

            @div(id := "jsondiv")
            @script(raw("""demo.DemoMain().json(document.getElementById("jsondiv"))"""))
        @sect{PythonParse}
            @p
                There is now an @a("example Python parser", href:="https://github.com/lihaoyi/fastparse/tree/master/pythonparse/shared/src/main/scala/pythonparse") available under a subproject in the repo. This is a good example of a real-world parser: parsing knotty syntax (including indentation-delimited blocks!), building an AST, and with heavy unit tests.

            @p
                PythonParse is currently compatible enough to parse all the python sources in Zulip, Ansible, Changes, Django, and Flask. It isn't published yet on maven central, but feel free to look at it if you want an idea of how to write a complex, real parser.

        @sect{CssParse}
            @div(id := "cssdiv")
            @script(raw("""demo.DemoMain().css(document.getElementById("cssdiv"))"""))

            @p
                @a("One more", href:="https://github.com/lihaoyi/fastparse/tree/master/cssparse/shared/src/main/scala/cssparse")
                too big for describing parser that parses CSS files and prints them adding the necessary spaces and tabs.
                In other words, making the file readable and good-looking.
                In process it builds internal AST that stores information about tags and rules in the given CSS,
                this AST isn't complete, because of complexity of initial CSS format,
                but it provides all the essential information about basic elements of file (blocks, selectors, rules).
                The correctness is tested by parsing and then printing several huge files including CSS from Bootstrap and Primer.

    @sect{API Highlights}

        @sect{Parser[T, ElemType, Repr]}
            @p
                Fastparse revolves around @hl.scala{Parser[T, ElemType, Repr]}s:
                a parser that can attempt to parser a value @hl.scala{T} from an input sequence of elements of type @hl.scala{ElemType}.
                The @hl.scala{Repr} type-parameter is responsible for output type in @sect.ref{Capture},
                since input is converted to the @hl.scala{IndexedSeq[ElemType]} or @hl.scala{Iterator[IndexedSeq[ElemType]]}
                during all parsing operations.
                These are defined as:

            @hl.ref(main/'core/"Parsing.scala", Seq("// Parser", "/*"), "// End Parser")
            @p
                The main external API is @hl.scala{.parse} for parsing regular arrays of data
                and @hl.scala{.parseIterator} for parsing streaming data. (@i{See also @sect.ref{Iterator Parsing}}).
                As you can see, apart from the @hl.scala{input} parameter,
                there are a few parameters that you can use to configure the parse.
                Apart from that, each @hl.scala{Parser[T, ElemType, Repr]} needs to implement @hl.scala{parseRec}
                which is a less-convenient but more-performant version that FastParse uses internally when performing a parse.

            @p
                There is @hl.scala{unapply} method in this class, you can read about it in @sect.ref{Unapply}.

            @p
                Although the core of @sect.ref{Parser[T, ElemType, Repr]} is simple,
                a lot of additional functionality is included in the @hl.scala{ParserApi[T, ElemType, Repr]} trait
                in order to make constructing parsers convenient and concise.

        @sect{ParserApi[T, ElemType, Repr]}
            @p
                Apart from the core @hl.scala{Parser},
                FastParse includes a large set of operations that you can perform on a @hl.scala{Parser}
                to make composing them more pleasant.
                These all live in @hl.scala{ParserApi}:

            @hl.ref(main/"ParserApi.scala", "trait ParserApi", "class ParserApiImpl")

            @p
                There are essentially all short-hand constructors for the parsers in the @hl.scala{object Parser} companion.
                This is the list of operators that you have available when writing your own parsers using FastParse.
            @p
                As mentioned in @sect.ref("Whitespace Handling"),
                you can choose to ignore the default set of operators by using @hl.scala{import fastparse.noApi}
                instead of @hl.scala{import fastparse.all}. That way you can use your own set of operators,
                e.g. the whitespace-sensitive operators described in that section.
        @sect{Parsing Results}
            @p
                The two kinds of a @hl.scala{Parsed} result reflect the status of a parse:
                a success (@hl.scala{Parsed.Success}) or a failure (@hl.scala{Parsed.Failure}).
                First, both classes can be used in pattern matching to discriminate the parse status.
                Second, they allow to extract the most commonly-used values.
                @hl.scala{Parsed.Success} provides the parsed value -
                the value you are probably most interesed in -
                and the index in the input string till where the parse was performed.
                @hl.scala{Parsed.Failure} allows you to retrieve the last parser that failed and the index where it failed.
                Additionally, failure provides an @hl.scala{Parsed.Failure.extra} field that provides precise details about the failure:
                line and column numbers (via @hl.scala{Extra.line} and @hl.scala{Extra.col})
                and most importantly a complete stack trace of the involved parsers, which is accessible via @hl.scala{Extra.traced}.

            @p
                An overview of @hl.scala{Parsed}:

            @hl.ref(main/'core/"Parsing.scala", Seq("object Parsed", "/*"), "/*")
            @hl.ref(main/'core/"Parsing.scala", Seq("case class Success", "/*"), "object Failure")

            @p
                Note how @hl.scala{Failure} only contains the parser which failed and a single index where the parse failed.
                Further debugging information is available via the @hl.scala{Failure.Extra} class.
                Especially the @hl.scala{TracedFailure} that is lazily-computed via @hl.scala{Extra.traced},
                provides valuable information: It performs a whole new parse on the input data with additional instrumentation,
                and provides additional insight into why the parse failed:

            @hl.ref(main/'core/"Parsing.scala", Seq("// TracedFailure", "/*"), "object TracedFailure")
            @p
                Computing the @hl.scala{Extra.traced} data is not done by default for performance reasons:
                the additional run takes about 3x longer than the initial run due to the instrumentation,
                for a total of 4x slowdown. If you want the information for debugging, though, it will be there.
    @sect{Debugging Parsers}
        @p
            The vast majority of your time working with FastParse, your parsers will be incorrect. This is almost by definition, because once your parser is correct, you'll be done and can go do something else with your life! Thus FastParse puts a lot of effort into making working with broken parsers as easy as possible

        @p
            Let's take an example Parser:

        @hl.ref(tests/"ExampleTests.scala", Seq("'debugging", "object Foo"), "check")

        @p
            This is a simple parser that parses some basic arithmetic expressions: @hl.scala{1+2}, @hl.scala{(1+2)+(3+4)}, etc.

        @p
            If we run the parser on a bad input, though, we get this:


        @hl.ref(tests/"ExampleTests.scala", Seq("'debugging", "original", "object Foo", "check", ""))

        @p
            As you can see, the error message is pretty generic: "i tried to parse @hl.scala{"(" ~ expr ~ ")"} or a @hl.scala{num} at index @hl.scala{0}". Why does it tell us that?

        @sect{Using Cuts}
            @p
                The answer is that as far as FastParse knows, you could have wanted either the @hl.scala{"(" ~ expr ~ ")"} or the @hl.scala{num} at that position, and it doesn't know which one. Thus even though it starts off parsing a paren, when that branch eventually fails (it tries to parse a @hl.scala{")"} at index 7, but finds a @hl.scala{"x"}) it backtracks out of the @hl.scala{"(" ~ expr ~ ")"} parser and then tries to parse @hl.scala{num}. When that fails, it doesn't know which side was "meant" to succeed, and so it gives up and just tells you both sides failed to parse.
            @p
                Although FastParse doesn't know which branch was meant to succeed, @i{we} know that once we've parsed a @hl.scala{"("}, it can no longer parse a number! Thus there's no point in backtracking and trying that side of the @hl.scala{|}. We can tell FastParse this fact by adding @sect.ref{Cuts} @hl.scala{~/} after @hl.scala{"("}

            @hl.ref(tests/"ExampleTests.scala", Seq("'debugging", "cuts", "object Foo"), "check")
            @p
                Now, once FastParse sees a @hl.scala{"("}, it can no longer backtrack! Thus it knows that whatever error occurs later, it @i{must} be because it failed to parse a @hl.scala{")"} and not because @hl.scala{num} failed. Then the error message becomes much more precise and useful:
            @hl.ref(tests/"ExampleTests.scala", Seq("'debugging", "cut", "object Foo", "check", ""))


        @sect{Using Log}
            @p
                We can add @sect.ref{Log} calls to make FastParse tell us a lot more about what a parser is doing. For example, if we want to know whenever a @hl.scala{side} or @hl.scala{expr} is being attempted, we can add @hl.scala{.log()} to those to parsers to find out:
            @hl.ref(tests/"ExampleTests.scala", Seq("'debugging", "log", "object Foo"), "Foo.expr.parse")

            @p
                Then when you run it on an invalid input:

            @hl.ref(tests/"ExampleTests.scala", Seq("'debugging", "log", "object Foo", "Foo.expr.parse"), "")

            @p
                You get a dump of everything the logged parsers are trying to do

            @hl.ref(tests/"ExampleTests.scala", Seq("'debugging", "log", "val expected", ""), "\"\"\"")


            @p
                @hl.scala{+} is when a parser is started, @hl.scala{-} is when it finishes with either a success or a failure. In the case of failure, it tells you what the stack was when it failed.
            @p
                The general strategy for adding @hl.scala{.log}s is:

            @ol
                @li
                    Is my parser misbehaving? This is usually obvious from seeing parse failures when there shouldn't be
                @li
                    Are any sub-parsers which I believe should be succeeding/failing/getting-called, aren't? Add logging to the sub-parsers. You can do this at the definition-site of the sub-parsers as shown above, or to the use-site e.g. @hl.scala{side.log("SIDE 1") ~ plus ~ side.log("SIDE 2")} if the parser is used in multiple places and you only want to log this usage.
                @li
                    Look at the logging, see some parser behaving strangely. Go to 1.

            @p


        @sect{Tracing}
            @p
                By default, on failure, FastParse only provides the index and the last parser which failed at that index. This is information FastParse already has and is thus cheap to provide, and often is enough to show what went wrong, and where. If you prefer row & column, you can trivially compute that from the input & index by counting newlines inside the input string.
            @p
                Often you want something more, though, and for that FastParse provides tracing, as described in the documentation of @sect.ref{Parsing Results}. By accessing the @hl.scala{.traced} lazy val on a @hl.scala{Failure}, FastParse will perform a whole second parse on the original input, starting from the same index, but with additional tracing code to keep track of what's happening. This typically costs ~2x as much as the original parse, so isn't done by default, but it's trivial to ask for it.
            @p
                For example, this is tracing being done on an invalid input we know will fail:

            @hl.scala
                val fail = Foo.expr.parse("(1+(2+3x))+4").asInstanceOf[fastparse.core.Parsed.Failure]
            @p
                We know that this input will fail, because our grammar (defined earlier) does not contain an @hl.scala{"x"} in it! It only handles numbers and @hl.scala{"+"} and parentheses. Let's see what information @hl.scala{.traced} gives us:

            @hl.scala
                > fail.traced.trace // The named parsers in the stack when it failed
                expr:0 / side:0 / expr:1 / side:3 / (")" | CharIn("0123456789")):7 ..."x))+4"

                > fail.traced.stack // Same as .trace, but as a List[Frame] rather than String
                List(
                 Frame(0,expr), // (1+(2+3x))+4
                 Frame(0,side), // (1+(2+3x))+4
                 Frame(1,expr), //  1+(2+3x))+4
                 Frame(3,side)  //    (2+3x))+4
                )

                > (fail.index, fail.lastParser) // Last index and last parser at which it failed
                (7, ")")         //        x))+4


            @p
                As you can see, tracing gives us a much more detailed view: every parser in the stack when the parse failed, what indices they were tried at. Apart from getting it as a readable string via @hl.scala{.trace}, you can also get it as structured data via @hl.scala{.stacK} in case you want to manipulate it programmatically.
            @p
                FastParse also provides the @hl.scala{.traceParsers} value, which tells you every single parser which @i{could} have succeeded at the index parsing failed. In thi
            @hl.scala
                > fail.traced.traceParsers // Every parser that could have succeeded at Failure#index
                List(")", CharIn("0123456789"))
            @p
                Thus, we can see that although FastParse last tried the @hl.scala{")"} parser, it earlier @i{also} tried the @hl.scala{CharIn("0123456789")} parser at the same spot. This makes perfect sense: if instead of @hl.scala{"x"} we had a digit of some kind, parsing could have continued! And we do not need to figure this out ourselves; FastParse knows and can tell you.
            @p
                Lastly, tracing gives you access to the @hl.scala{.fullStack} of the failure, which contains @i{every} parser in the stack when it failed, not just the ones with names!
            @p
                Every expression in a fastparse parser is itself a parser: @hl.scala{"("} is a parser, @hl.scala{"(" ~ expr ~ ")"} is a parser, and so on. With @hl.scala{.fullStack}, we can see in great detail what FastParse was trying to do when it failed:

            @hl.scala
                > fail.traced.fullStack // Every single parser in the stack when it failed
                List(
                 Frame(0,expr),   Frame(0,expr), Frame(0,side ~ plus ~ side),
                 Frame(0,side),   Frame(0,"(" ~/ expr ~/ ")" | num), Frame(1,"(" ~/ expr ~/ ")"),
                 Frame(1,expr),   Frame(1,expr), Frame(3,side ~ plus ~ side),
                 Frame(3,side),   Frame(3,"(" ~/ expr ~/ ")" | num), Frame(7,"(" ~/ expr ~/ ")")
                )
                > (fail.index, fail.lastParser) // Last index and last parser at which it failed
                (7, ")")         //        x))+4

        @sect{Use Cases}
            @p
                What's the purpose of all this detailed error reporting? The goal is three-fold:
            @ul
                @li
                    You will want to know why parsers as misbehaving while you're writing them so you can fix bugs. Often @hl.scala{.traced.trace} is enough, but you can dig in more deeply if you wish to.
                @li
                    You can use the detailed error traces to your users when they enter invalid input. For example, instead of just @i{"Syntax error at column @hl.scala{7}"} You can say @i{"Syntax error at column @hl.scala{7}, expected @hl.scala{(")" | CharIn("0123456789")}, while trying to parse a @hl.scala{side} at column @hl.scala{3}, while trying to parse an @hl.scala{expr} at column @hl.scala{1}, ..."}. Naturally, you do not need to overwhelm the user with debug information, but now you have the power to reveal as much or as little as you want.

                @li
                    You can customize the experience of your users when they enter invalid input! For example, if I know that the rule @hl.scala{side} failing @i{usually} means the user made some common mistake, I can easily check for that via @hl.scala{fail.traced.stack.contains(_.parser == Foo.side)} and display a more helpful error @i{"Maybe try X?"} if it's found. No need to embed your error-reporting deep in the parser, just inspect the @hl.scala{stack} and find out after the fact.
            @p
                In general, FastParse's error reporting is detailed and structured. As a @i{developer}, most of your time spent interacting with your parser is when it is incorrect and throwing errors at you. As a @i{user}, most of your time spent interacting with the parser is when your input is incorrect and it is throwing errors at you. This is almost self-evident, since once your parser is correct or your input is correct you're done and go do other things
            @p
                Thus, FastParse makes an effort to make the error reporting both detailed and structured. This means as a developer you can quickly diagnose problems, and (if you wish to) put in effort to use the structured errors to help @i{your users} diagnose problems. That makes life better for everybody.

    @sect{Performance}
        @p
            FastParse will never be able to compete with hand-written recursive descent parsers for speed. However, it's no slouch either; here's a comparison of FastParse with alternatives, using Parboiled2's JSON parsing benchmark, which parses a ~21,500 line JSON file:

        @table(width := "100%")
            @thead
                @th{Benchmark}@th{Score}@th{Error}
            @tbody
                @tr
                    @td{fastparse}@td{80.536}@td{± 0.942}
                @tr
                    @td{fastparse-no-trace}@td{89.873}@td{± 0.875}
                @tr
                    @td{argonaut}@td{164.092}@td{± 2.869}
                @tr
                    @td{json4s-jackson}@td{285.637}@td{± 3.954}
                @tr
                    @td{json4s-native}@td{142.964}@td{± 2.076}
                @tr
                    @td{parboiled2}@td{87.586}@td{± 1.176}
                @tr
                    @td{scala-parser-combinators}@td{0.976}@td{± 0.018}
                @tr
                    @td{spray-json}@td{189.784}@td{± 2.825}


        @p
            These numbers are the number of iterations/second of parsing a sample @code{test.json} file, averaged over 200 runs. As you can see, the FastParse based parser comes within a factor of 4 of the fastest hand written parser (Jackson), is just as fast as the Parboiled2 based parser (slightly faster/slower depending if full tracing is enabled), and is almost 100x faster than the scala-parser-combinators library.

        @p
            In exchange for the perf hit compared to hand-rolled solutions, you get the @sect.ref("Json", "short, super-simple parser definition"), and excellent error free error reporting. While for super-high-performance use cases you may still want a hand-rolled parser, for many ad-hoc situations a FastParse parser would do just fine. Remember, even at "only" 89 iterations per second that is still parsing 1,900,000 lines of JSON every second!

        @p
            A similar speed ratio can be seen in parsing a @a("sample Scala file", href:="https://github.com/scala-js/scala-js/blob/master/compiler/src/main/scala/org/scalajs/core/compiler/GenJSCode.scala") using FastParse, Parboiled2 and Scalac's inbuilt hand-written Scala-language parser:

        @table(width := "100%")
            @thead
                @th{Benchmark}@th{Score}@th{Error}
            @tbody
                @tr
                    @td{fastparse}@td{320.7}@td{15.4}
                @tr
                    @td{fastparse-no-trace}@td{434.7}@td{23.4}
                @tr
                    @td{parboiled2}@td{1354}@td{7.97}
                @tr
                    @td{scalac}@td{4888}@td{113}

        @p
            These numbers are the number of iterations over 30 seconds, average of 4 runs, with 2 runs of warmup (discarded). FastParse performs worse here, at 11.5x slower than Scalac's in-built parser, and 3x slower than the equivalent Parboiled2-based parser. Depending on what you're doing, that may or may not be a problem: ScalaParse still makes progress at 57,027 lines of Scala per second, which despite being slower than the others is still blazing fast.

    @sect{Internals}
        @p
            FastParse's internals are straightforward, at less than 1000 lines of code. Nonetheless, its design is unlike any other combinator library I've seen: externally immutable, pure-functional parser-combinators with mutable, highly-optimized internals.

        @sect{Abstraction}
            @p
                Actually, each of the previously described basic parsers is a special case of more abstract
                corresponding parser from the inner Api that can be used for the arbitrary type of elements in the input.
                Parsers for @hl.scala{String} input has @hl.scala{Char} as type-parameter in this Api,
                parsers for @hl.scala{Array[Byte]} has @hl.scala{Byte} and etc.
            @p
                There is no need to explain again how these abstract parsers work,
                because it's exactly the same as in the @hl.scala{String} or @hl.scala{Array[Byte]} case,
                the only difference is that instead of @hl.scala{Char} or @hl.scala{Byte} we consider arbitrary class.
                Names of these parsers are also the same except of
                @ul
                    @li
                        @hl.scala{AnyElem} for @hl.scala{AnyChar} and @hl.scala{AnyByte}
                    @li
                        @hl.scala{ElemPred} for @hl.scala{CharPred} and @hl.scala{BytePred}
                    @li
                        @hl.scala{ElemIn} for @hl.scala{CharIn} and @hl.scala{ByteIn}
                    @li
                        @hl.scala{ElemsWhile} for @hl.scala{CharsWhile} and @hl.scala{BytesWhile}
                    @li
                        @hl.scala{SeqIn} for @hl.scala{StringIn}
                but you can, of course, use these abstract versions of names wherever you want.


        @sect{Fast Interpreter}
            @p
                FastParse is designed as a fast, immutable interpreter. That means
            @ul
                @li
                    It does not do significant transformations of the grammar. The structure of the parser you define is the structure that will run. No transformation at compile time, no transformations at run-time.
                @li
                    It provides fast primitives like @sect.ref{CharsWhile}, that you can drop in many places to speed up otherwise slow bulk operations (e.g. parsing whitespace, identifiers).
                @li
                    Error reported is straightforward: the last index that it does not backtrack out of is the index that is reported, and the parser at that point is the parser that is reported.

            @p
                In theory, it could be possible to perform either compile-time or initialization-time (before actually parsing) optimizations on the parser to improve performance. So far, I have not managed to find a scheme that has a significant improvement at an acceptable cost in terms of complexity. Apart from trivial de-sugarings (e.g. merging together @hl.scala{(p1 | p2) | p3} into a single @hl.scala{Either} node) what you write is what gets run

        @sect{External Immutabiliy}

            @p
                FastParse presents a pure-functional, immutable external API to the user. That means that you can call @hl.scala{Parser[T]#parse} and not worry about having to set up neccessary state or instantiating objects. You take a @hl.scala{Parser[T]}, call @hl.scala{.parse}, and get a @hl.scala{Success[T]} or @hl.scala{Failure}

            @p
                However, immutability poses a challenge: immutability usually involves lots of "copy & update" operations rather than "mutation" operations, and on the JVM that means excessive garbage generation and collection. This is harmful for performance.

            @p
                Thus FastParse performs some tricks internally to save allocations: the immutable @hl.scala{Parser.Success} and @hl.scala{Parser.Failure} result types are actually interfaces hiding @hl.scala{Parser.Mutable.Success} and @hl.scala{Parser.Mutable.Failure} implementations, which have entirely mutable fields.

            @p
                This means that the same @hl.scala{Parser.Mutable.Success} and @hl.scala{Parser.Mutable.Failure} objects are shared throughout an entire parsing run, mutated as the parse progresses, while the external user only sees an immutable facade. This also means that a run of the large-and-complex @sect.ref{ScalaParse} on a hundreds-of-kb source file results in exactly @i{three} allocations in all: one @hl.scala{Parser.Mutable.Success}, one @hl.scala{Parser.Mutable.Failure}, and one @hl.scala{Ctx} object holding them together.

        @sect{Internal Optimizations}
            @p
                FastParse does some things that take advantage of the type-directed nature of the result-aggregation: while @hl.scala{Parser[T].rep} returns a @hl.scala{Parser[Seq[T]]} for an arbitrary @hl.scala{T}, there is a short circuit such that @hl.scala{Parser[Unit].rep} simple returns @hl.scala{Parser[Unit]}. This lets the common case of "parsing things, not caring about the result" avoid the allocation, while still allowing you to stick some other type in there (e.g. @hl.scala{Any}) if you really do care about the bucket-of-@hl.scala{Unit}s.

            @p
                FastParse also takes advantage of the fact that @hl.scala{Parser}s are immutable. That makes it feasible to make instantiation mildly-expensive, since each one only gets instantiated once rather than per-parse. As an example, @sect.ref{CharIn}, @sect.ref{CharPred} and @sect.ref{CharsWhile} all have their predicate converted to an identical bit-set to make character lookups extremely fast. Similarly, @sect.ref{StringIn} gets converted into a Trie in order to allow one-pass matching of dozens of strings at the same time.
            @p
                These operations are not cheap: the bitsets easily take a few KB of memory each, and involve 65k iterations to fill them in. However, since @hl.scala{Parser}s are immutable, this one-time-cost goes from "ridiculous" to "acceptable". All these internal optimizations are completely opaque to the user, who (apart from performance) never need to think about them.


    @sect{Comparisons}
        @p
            FastParse differs from all other parser-combinator libraries in the Scala universe, in quite substantial ways:

        @ul
            @li
                Compared to @a("Parboiled2", href:="https://github.com/sirthias/parboiled2"), FastParse does not use macros to compile-time-generate fast parser code. Rather, it acts as an efficient interpreter, sacrificing some speed (1-4x slower) for huge amounts of usability. Parboiled2 in particular has @a("usability problems and bugs", href:="https://groups.google.com/forum/#!msg/scala-internals/4N-uK5YOtKI/9vAdsH1VhqAJ") that make it excruciating difficult to use, and also does not support higher-order rules. FastParse suffers from none of these problems.
            @li
                @a("Parboiled1", href:="https://github.com/sirthias/parboiled/wiki") is a Java library, and does not/cannot work on Scala.js
            @li
                @a("scala-parser-combinators", href:="https://github.com/scala/scala-parser-combinators") is similar, but poorly executed. It is ~100x slower than FastParse, has an awkward inheritance-based API, and is full of bugs despite being half a decade old. FastParse is faster, has self-contained pure-functional parsers, and fixes bugs e.g. by having the @hl.scala{.log} operator actually work.

@sect{Writing Byte Parsers}
    @p
        In the same way as the @hl.scala{String} parsers we can build @hl.scala{Array[Byte]} or simply @hl.scala{Byte} parsers.
    @p
        The first example will be about parsing a single byte sequence
    @hl.ref(bytetests/"ByteTests.scala", Seq("'sequence", ""))

    @p
        As you can see it has the very same structure as previous @hl.scala{String} parsers,
        but with several additional features.
        The first is new word @hl.scala{BS} or @hl.scala{ByteSeq} that merely means alias for @hl.scala{Array[Byte]},
        the second is new function for convenient conversion from @hl.scala{String} to @hl.scala{Array[Byte]} - @hl.scala{strToBytes}.
    @p
        Of course, you aren't restricted to use only them, you are free to create Array of Byte by any method or function,
        but, naturally, it's recommended to follow the one uniform style and @hl.scala{BS} with @hl.scala{strToBytes} is the good example of it.

    @sect{New Parsers}
        @p
            Byte Parsers doesn't bring anything new to the basic set of parsers.
            @sect.ref{Optional}, @sect.ref{Repeat}, @sect.ref{Capture} and ect. are still here with the same logic,
            but there are some new names for @hl.scala{Byte} versions of some of them.
            It just a replacement of "Char" substring to the "Byte", that's all, so
            @ul
                @li
                    @hl.scala{AnyChar} becomes @hl.scala{AnyByte}
                 @li
                    @hl.scala{CharPred} becomes @hl.scala{BytePred}
                 @li
                    @hl.scala{CharIn} becomes @hl.scala{ByteIn}
                 @li
                    @hl.scala{CharsWhile} becomes @hl.scala{BytesWhile}
                 @li
                    @p
                        @hl.scala{StringIn} becomes @hl.scala{SeqIn}
                    @i
                        It isn't a simple replacement of substrings, and the reason for this is described in @sect.ref{Abstraction}.

         @p
            For instance, the basic parser with @hl.scala{AnyByte}
         @hl.ref(bytetests/"ByteTests.scala", Seq("'anychar", ""))

    @sect{Words and Dwords}
        @p
            Many byte formats use such concepts as Word and Dword that just means 2 and 4 bytes,
            so Api for Byte Parsers provides special parsers for this case.
            They called @hl.scala{Word} and @hl.scala{Dword}
            and is defined as @hl.scala{AnyByte.rep(exactly=2)} and @hl.scala{AnyByte.rep(exactly=4)},
            which means they consumes any 2 or 4 byte.
            When it's needed to convert Word or Dword to integer value (@hl.scala{Short} and @hl.scala{Int}),
            you can use @hl.scala{WordI} and @hl.scala{DwordI} parsers,
            but the problem is that there are
            @a("two standards of ordering bytes", href:="https://en.wikipedia.org/wiki/Endianness"),
            and they gives different results on equal byte sequences.
            Thus there are two special packages @hl.scala{fastparse.ByteUtils.BE._} for Big-Endian
            and @hl.scala{fastparse.ByteUtils.LE._} for Little-Endian,
            each has its own @hl.scala{WordI} and @hl.scala{DwordI} parser for each case.

    @sect{Example Byte Parsers}
        @sect{BmpParser}
            @div(id := "bmpdiv")
            @script(raw("""demo.DemoMain().bmp(document.getElementById("bmpdiv"))"""))
            @i
                Given form accepts BMP files and prints short info about it (width, height and etc.).
                If you haven't any bmp around, you can download classic
                @a("lena", href:="https://raw.githubusercontent.com/lihaoyi/fastparse/master/byteparse/jvm/src/test/resources/lena.bmp").

            @p
                @hl.scala{BmpParser} is a good first example of byte parser, it's not small, but structure is pretty simple.

            @hl.scala{import fastparse.ByteUtils.LE._}

            @p
                First of all we import package for Little-Endian support, because BMP format use it.

            @hl.ref(bytemain/"BmpParser.scala", "val bmp")

            @p
                Bmp file consists of two headers (file header and info header) and pixels in rows with padding,
                the difficulties are that there are several versions of headers and the parser should distinct them and
                process them correctly, and that the size and padding of rows in bmp file depends on information from header.

            @hl.ref(bytemain/"BmpParser.scala", "val fileHeader", "def bmpRow")

            @p
                The first problem is reflected in similar parsers describing 5 versions of info header
                (@hl.scala{v2HeaderPart}, @hl.scala{v2Header}, @hl.scala{v3HeaderPart}, @hl.scala{v3Header}...).

            @hl.ref(bytemain/"BmpParser.scala", "def bmpRow", "val bmp")

            @p
                The second problem in the @hl.scala{bmpRow} function that computes the parameters of row and creates parser on a fly.

            @p
                Note also few tricks for parsing binary data.
            @ul
                @li
                    @b
                        Most of main elements in bmp format has very simple and plain structure. @br
                     For instance @hl.scala{fileHeader} and @hl.scala{infoHeaderPart}
                     are just sequences of @hl.scala{AnyDwordI} or @hl.scala{AnyWordI}
                @li
                    @b
                        The extensive usage of @hl.scala{.rep(exactly=...)}.@br
                    This is due to the fact that many binary formats depends on constant-sized blocks
                    and the easiest and fastest method to parse them is to write @hl.scala{.rep(exactly=...)}.
                @li
                    @b
                        The same extensive usage of @hl.scala{.flatMap}.@br
                    @hl.scala{flatMap} allows to retrieve data from one parser and pass it to the next.
                    The most popular and primitive example is dynamic-sized array with length written at the beginning.
                    Similar algorithm is used in the @hl.scala{bmp} when header information is passed to the @hl.scala{bmpRow}
                    that returns new parser for row in this particular bmp file.

        @sect{ClassParser}
            @p
                @div(id := "clssdiv")
                @script(raw("""demo.DemoMain().clss(document.getElementById("clssdiv"))"""))
                @i
                    Given form accepts .class bytecode files for java language and prints names of all fields and methods with their descriptors.
                    If you haven't any .class files around, you can download
                    some examples (
                    @a("Book.java", href:="https://github.com/lihaoyi/fastparse/raw/master/byteparse/shared/src/test/resources/Book.java"),
                    @a("Book.class", href:="https://github.com/lihaoyi/fastparse/raw/master/byteparse/shared/src/test/resources/Book.class"),
                    @a("Book2.java", href:="https://github.com/lihaoyi/fastparse/raw/master/byteparse/shared/src/test/resources/Book2.java"),
                    @a("Book2.class", href:="https://github.com/lihaoyi/fastparse/raw/master/byteparse/shared/src/test/resources/Book2.class"),
                    @a("CodeTest.java", href:="https://github.com/lihaoyi/fastparse/raw/master/byteparse/shared/src/test/resources/CodeTest.java"),
                    @a("CodeTest.class", href:="https://github.com/lihaoyi/fastparse/raw/master/byteparse/shared/src/test/resources/CodeTest.class"))

            @p
                @a("Another byte parser", href:="https://github.com/lihaoyi/fastparse/tree/master/byteparse/shared/src/main/scala/byteparse/classparse")
                that is present in the FastParse is @hl.scala{ClassParser}.
                It's quite a complex parser that process .class files from java bytecode.
                It's able to retrieve almost full information about given class including all methods, fields, subclasses, code
                and pack it into the convenient AST.
                On the similarity with other big parsers it has good set of unit-tests
                with tests which compile real projects from github (joda-time, junit4, jenkins and etc.)
                and check each built file.

@sect{ScalaParse}

    @div(id := "scaladiv")
    @script(raw("""demo.DemoMain().scalaparser(document.getElementById("scaladiv"))"""))

    @p
        ScalaParse is a parser for the entire Scala programming language, written using FastParse. This is notable for a few reasons:

    @ul
        @li
            ScalaParse is about 700 lines of code, making it about 1/10th the size of the default parser in @hl.scala{tools.nsc.Global}
        @li
            ScalaParse runs about @sect.ref("Performance", "1/8th the speed") of of the default parser in @hl.scala{tools.nsc.Global}
        @li
            ScalaParse has excellent error reporting due to proper use of @sect.ref{Cuts}, without any code explicitly dedicated to error reporting
    @p
        ScalaParse does not currently generate an AST. As you can see, the parse result above is listed as @hl.scala{undefined}. However, that does not make it useless! Even without generating an AST, ScalaParse can be used to:

    @ul
        @li
            Check for errors! ScalaParse provides excellent error reporting on parses, equal or better than that provided by the tools.nsc.Global parser, entirely for free.
        @li
            Prototype extensions to the Scala grammar! Unlike the default tools.nsc.Global parser, ScalaParse makes it trivial to add new rules at various sections of the grammar.
        @li
            Manipulate Scala code sections! It's trivial to wrap various rules in ScalaParse in an @sect.ref{Capture} and use it to pull out the relevant bits of a Scala file for you to use.


    @sect{Using ScalaParse}
        @p
        To begin using ScalaParse, add

        @hl.scala
            "com.lihaoyi" %% "scalaparse" % "@fastparse.Constants.version"

        @p
            To your SBT configuration. To use with Scala.js, you'll need

        @hl.scala
            "com.lihaoyi" %%% "scalaparse" % "@fastparse.Constants.version"

@sect{Change Log}
    @sect{0.4}
        @ul
            @li
                New @sect.ref{CssParse} in cssparse module
            @li
                More abstract version of @hl.scala{Parser} class, that becomes @sect.ref{Parser[T, ElemType, Repr]},
                with changing all basic parsers in Combinators, Intrinsics and Terminals to conform this new definition.
            @li
                Convenient Api for @sect.ref{Writing Byte Parsers}.
            @li
                New @sect.ref{BmpParser} in byteparse module.
            @li
                Java bytecode parser of .class files @sect.ref{ClassParser} in byteparse.classparse module.
            @li
                Support for parsing streaming data or @sect.ref{Iterator Parsing}.
            @li
                @sect.ref{Unapply} method by @a("volth", href:="https://github.com/volth").
            @li
                Sharding of build configuration to several separate groups of tests
    @sect{0.3.7}
        @ul
            @li
                Bump version of @code{sourcecode} from @code{0.1.0} to @code{0.1.1}
    @sect{0.3.6}
        @ul
            @li
                Fix @b{#77}: deduplicate traceParsers in WhitespaceAPI to prevent stack overflow, by @a("Jeroen Rosenberg", href:="https://github.com/jeroenr")
    @sect{0.3.5}
        @ul
            @li
                Minor improvements to error-reporting in Scalaparse; error messages inside tuple-types and refinement-types should be slightly more precise
    @sect{0.3.4}
        @ul
            @li
                Fix @b{#69}: performance problem in the @hl.scala{StringsIn} parser, which resulted in initialization time exponential relative to the length of the longest string, by @a("Rudiger Klaehn", href:="https://github.com/rklaehn")
    @sect{0.3.3}
        @ul
            @li
                @b{#66} Bugfix: @hl.scala{Parser.rep} now handles max=0 properly, by @a("Martin Senne", href:="https://github.com/ProjectZetta/")

            @li
                Further restructuring of @hl.scala{Parsed.Result} by @a("Martin Senne", href:="https://github.com/ProjectZetta/")
                 @ul
                     @li
                         Object @hl.scala{Result} has been renamed to @hl.scala{Parsed}
                                
                     @li
                         Former @hl.scala{Result} has moved to @hl.scala{Parsed}.
                                
                     @li
                         Methods for position retrieval @hl.scala{line} and @hl.scala{col} have moved to @hl.scala{Failure.Extra}

            @li
                @b{#59} Fix @hl.scala{fastparse.core.Result.Failure.formatParser()} throwing @hl.scala{UnsupportedOperationException} on receiving an empty string as an input, by @a("solar", href:="https://github.com/solar")
            @li
                @b{#61} Added the @sect.ref{Opaque} combinator, which allows to provide more high-level error messages, by @a("Nick Stanch", href:="https://github.com/stanch")
            @li
                @hl.scala{Result.Failure} has been restructured: Less-commonly-used properties like @hl.scala{input} and @hl.scala{traced} have been aggregated into an @hl.scala{Result.Failure.Extra} object, simplifying pattern matching. By @a("Martin Senne", href:="https://github.com/ProjectZetta/")

    @sect{0.3.2}
        @ul
            @li
                Slightly better parsing of triple-quote strings in Scalaparse
            @li
                Added an alias for @hl.scala{type Result[T]} to match the @hl.scala{val Result} inside @hl.scala{fastparse.all}
    @sect{0.3.1}
        @ul
            @li
                @b{#47} Upgraded to Scala.js 0.6.5, removed unnecessary @code{CharPredicate}s
            @li
                @b{#42} Renamed @hl.scala{a ~! b} to @hl.scala{a ~/ b} to avoid confusion with @hl.scala{a ~ !b}
            @li
                @hl.scala{Failure} objects now expose the @hl.scala{.line} and @hl.scala{.col} attributes, in addition to the raw @hl.scala{.index}, and display these in the default trace messages
            @li
                @b{#27} @hl.scala{.rep} now can take a @hl.scala{max} in addition to a @hl.scala{min}
            @li
                @b{#40} @hl.scala{.log} now properly displays the proper snippet of text when propagating failure upward
    @sect{0.2.1}
        @ul
            @li
                Simplified ScalaParse internals slightly
            @li
                @hl.scala{Parser#get} now throws a custom @hl.scala{SyntaxError} with relevant metadata, instead of a plain @hl.scala{Exception}
            @li
                @hl.scala{WhitespaceApi}'s @hl.scala{WL} value no longer leaks out when you import from it
    @sect{0.2.0}
        @ul
            @li
                Default import changed from @hl.scala{import fastparse._} to @hl.scala{import fastparse.all._}, to make space for @hl.scala{import fastparse.noApi._}
            @li
                Major changes to parser internals: the internal representation of parse results in @hl.scala("Mutable.{Success, Failure}") has been split off from the immutable external represenation @hl.scala("Result.{Success, Failure}")
            @li
                Error-reporting has been overhauled, and is greatly improved at the cost of being more expensive. Detailed errors now require a second parse with instrumentation
            @li
                The cheap & spartan error data in @hl.scala{Result.Failure} has been split out from the expensive but detailed error traces in @hl.scala{Result.Failure#traced}.
            @li
                @hl.scala{.log()} now uses the parser's own @hl.scala{.toString} by default if you don't pass in a tag, for convenience.
            @li
                Added the ability to exclude the default parser operators via @hl.scala{import fastparse.noApi._}, allowing you to import custom sets of operators tailored to your needs.
            @li
                Introduced the @hl.scala{fastparse.WhitespaceApi} class, which replaces the default set of operators with a new set which eagerly consumes whitespace between parsers.
            @li
                Updated ScalaParse to use @hl.scala{fastparse.WhitespaceApi}, resulting in much more precise error locations. Errors are now positioned before the characters which failed, rather than before the preceding whitespace, and syntax errors in comments now provide better errors
            @li
                Added unit tests and examples/demos of @sect.ref{Whitespace Handling} and @sect.ref{Indentation Grammars}
            @li
                Added @sect.ref{Filter} to the API, to complement @sect.ref{Map} and @sect.ref{FlatMap}
    @sect{0.1.7}
        @ul
            @li
                More fixes for ScalaParse, added more projects to test suite
            @li
                Auto-generate @hl.scala{Sequencer} instances up to 22
            @li
                Removed unnecessary runtime utest dependency
    @sect{0.1.6}
        @ul
            @li
                Introduced five new projects into the test suite: ScalaIDE, GitBucket, Scalding, Scaloid, Marathon
            @li
                Fixed bug in ScalaParse around using function @hl.scala{=>} types as type ascriptions
            @li
                Added ability to @hl.scala{instrument} parsers, in order to gather out-of-band information about them e.g. for debugging or profiling
            @li
                Added @hl.scala{IgnoreCase} combinator, for case-insensitive string matching
            @li
                Cross-published for Scala 2.10

